\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{cvpr}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{fontspec}
\usepackage{times}
\usepackage{multirow}
\setmainfont{Times New Roman}
\newcommand{\tabincell}[2]{\begin{tabular}{@{}#1@{}}#2\end{tabular}}
\usepackage{stfloats}
\usepackage[pagebackref=true,colorlinks,linkcolor=red,citecolor=green,breaklinks=true,bookmarks=false]{hyperref}
\cvprfinalcopy % *** Uncomment this line for the final submission
\def\cvprPaperID{****} % *** Enter the CVPR Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}
% Pages are numbered in submission mode, and unnumbered in camera-ready
%\ifcvprfinal\pagestyle{empty}\fi
\setcounter{page}{1}
\title{Deeply Supervised Salient Object Detection}
\author{Hongzhi Liu\\\\
Jun 6, 2018}

\begin{document}
%%%%%%%%% TITLE
\maketitle
%\thispagestyle{empty}
\begin{abstract}
	Recent progress on saliency detection is substantial, benefiting mostly from the explosive development of Convolutional Neural Networks (CNNs). Semantic segmentation and saliency detection algorithms developed lately have been mostly based on Fully Convolutional Neural Networks (FCNs). Today, I read a thesis written by Mingming Cheng, who is from Nankai University. His team propose a new saliency method by introducing short connections to the skip-layer structures within the HED architecture. Their method produces state-of-the-art results on 5 widely tested salient object detection benchmarks, with advantages in terms of efficiency, effectiveness and simplicity over the existing algorithms. Furthermore, based on their method, HUAWEI successfully developed intelligent self photo applications which is used in flagship mobile phones, providing powerful support for HUAWEI's intelligent photo taking.
\end{abstract}
%%%%%%%%% BODY TEXT
\section{Overview of the Framework}
The goal in salient object detection is to identify the most visually distinctive objects or regions in an image. Salient object detection methods commonly serve as the first step for a variety of computer vision applications. Inspired by cognitive studies of visual attention, computational saliency detection has received great research attention in the past two decades. The Holistically-Nested Edge Detector (HED) \cite{Saining2015Holistically} model, which explicitly deals with the scale space problem, has lead to large improvements over generic FCN models in the context of edge detection. However, the skip-layer structure with deep supervision in the HED model does not lead to obvious performance gain for saliency detection.

As demonstrated in Fig.\ref{fig:1}, Dr. Cheng observes that deeper side outputs encodes high level knowledge and can better locate salient objects and shallower side outputs capture rich spatial information. This motivated him to develop a new method for salient object detection by introducing short connections to the skip-layer structure within the HED architecture. By having a series of short connections from deeper side outputs to shallower ones, our new framework offers two advantages mentioned in the paper \cite{Hou2016Deeply}. One is that high-level features can be transformed to shallower side-output layers. And the other one is that shallower side-output layers can learn rich low-level features.
\begin{figure*}
	\begin{center}
		\includegraphics[scale=0.5,width=1\linewidth]{1.png}
	\end{center}
	\caption{Visual comparison of saliency maps produced by the HED-based method and ours. Though saliency maps produced by deeper (4-6) side output (s-out) look similar, because of the introduced short connections, each shallower (1-3) side output can generate satisfactory saliency maps and hence a better output result.}
	\label{fig:1}
\end{figure*}

%------------------------------------------------------------------------
\section{Deep Supervision with Short Connections}

As pointed out in most previous works, a good salient object detection network should be deep enough such that multi-level features can be learned. Further, it should have multiple stages with different strides so as to learn more inherent features from different scales.

\subsection{HED-based saliency detection}
The team propose a top-down method to reasonably combine both low-level and high-level features for accurate saliency detection. They shall start out with the standard HED architecture as well as its extended version, a special case of this work, for salient object detection and gradually move on to the proposed architecture. The side objective function of HED can be given by as Equation~\ref{fun}:
\begin{equation}
L_{side}(W,w)=\sum_{m=1}^{M}\alpha_ml_{side}^{(m)}(W,w^{(m)}),  \label{fun} 
\end{equation}
where $\alpha_m$ is the weight of the $m$th side loss and $l_{side}^{(m)}$ side denotes the image-level class-balanced cross-entropy loss function for the mth side output. Besides, a weightedfusion layer is added to better capture the advantage of each side output. The fusion loss at the fusion layer can be expressed as Equation~\ref{fuse}:
\begin{equation}
L_{fuse}(W,w,f)=\sigma(Z,h(\sum_{m=1}^{M}f_mA_{side}^{(m)})), \label{fuse} 
\end{equation}
Therefore, the final loss function can be given by as Equation~\ref{loss}:
\begin{equation}
L_{final}(W,w,f)=L_{fuse}(W,w,f)+L_{side}(W,w), \label{loss} 
\end{equation}
HED connects each side output to the last convolutional layer in each stage of the VGGNet \cite{simonyan2014very}. Each side output is composed of a one-channel convolutional layer with kernel size $1\times 1$ followed by an up-sampling layer for learning edge information.

\begin{table}[tp]
	\begin{center}
	\caption{The performance of different architectures on PASCALS dataset \cite{Li2014The}. ``*'' represents the pattern used in this paper.} \label{Com}
	\begin{tabular}{c|c|c}
		\hline
		No. & Architecture & $F_\beta$ \\
		\hline
		1 & Hypercolumns \cite{Hariharan2014Hypercolumns} & 0.818 \\
		2 & Original HED \cite{Saining2015Holistically} & 0.791 \\
		3  & Enhanced HED & 0.816 \\
		4 & Pattern 1 & 0.816 \\
		5 & Pattern 2 & 0.824 \\
		6 & Pattern 3* & 0.830 \\
		\hline
	\end{tabular}
\end{center}
\end{table}

\subsection{Short Connections}

Our approach is based on the observation that deeper side outputs are capable of finding the location of salient regions but at the expense of the loss of details, while shallower ones focus on low-level features but are short of global information. These phenomenons inspire us to utilize the following way to appropriately combine different side outputs such that the most visually distinctive objects can be extracted.

\section{Experimental Results of the Method}

The team's experiment with different design options and different short connection patterns to illustrate the effectiveness of each component of our method. The performance is listed in Table\ref{Com}. As can be seen from Table\ref{Com}, with the increase of short connections, their approach gradually achieves better performance.



{\small
\bibliographystyle{ieee}
\bibliography{egbib}
}

\end{document}
